{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1020207c-b542-468a-a885-00d6bbdb7270",
   "metadata": {},
   "source": [
    "# Apache Spark intro\n",
    "\n",
    "\n",
    "Apache Spark is a general-purpose, in-memory computing engine. Spark can be used with Hadoop, Yarn and other Big Data components to harness the power of Spark and improve the performance of your applications. It provides high-level APIs in Scala, Java, Python, R, and SQL.\n",
    "\n",
    "**Spark Architecture**\n",
    "\n",
    "Apache Spark works in a master-slave architecture where the master is called “Driver” and slaves are called “Workers”. The starting point of your Spark application is `sc`, a Spark Context Class instance. It runs inside the driver.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1192/0*XzNeTtwEgIy5yWR_)\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1266/0*-PltnPR9row8iUDo)\n",
    "\n",
    "**Apache Spark**: \n",
    "Sometimes also called Spark Core. The Spark Core implementation is a RDD (Resilient Distributed Dataset) which is a collection of distributed data across different nodes of the cluster that are processed in parallel.\n",
    "\n",
    "\n",
    "**Spark SQL**: \n",
    "The implementation here is DataFrame, which is a relational representation of the data. It provides functions with SQL like capabilities. Also, we can write SQL like queries for our data analysis.\n",
    "\n",
    "\n",
    "**Spark Streaming**: \n",
    "The implementation provided by this library is D-stream, also called Discretized Stream. This library provides capabilities to process/transform data in near real-time.\n",
    "\n",
    "\n",
    "**MLlib**: \n",
    "This is a Machine Learning library with commonly used algorithms including collaborative filtering, classification, clustering, and regression.\n",
    "\n",
    "**GraphX**: \n",
    "This library helps us to process Graphs, solving various problems (like Page Rank, Connected Components, etc) using Graph Theory.\n",
    "\n",
    "\n",
    "Let’s dig a little deeper into Apache Spark (Spark Core), starting with RDD.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb327a64-0391-448e-9867-57c101e02675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b65c12-4ace-42b6-8ff4-cc1d4c8d4ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"myAppName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f310b0f1-9371-4e1f-b27c-44bdf5e1c06d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://1bdbcfb9b532:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>myAppName</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=myAppName>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c170258-541d-4dc0-ba69-73432a3112b5",
   "metadata": {},
   "source": [
    "### RDD\n",
    "\n",
    "- Resilient Distributed Dataset\n",
    "- Podstawowa abstrakcja oraz rdzeń Sparka\n",
    "- Obsługiwane przez dwa rodzaje operacji:\n",
    "    - Akcje:\n",
    "        - operacje uruchamiająceegzekucję transformacji na RDD\n",
    "        - przyjmują RDD jako input i zwracają wynik NIE będący RDD\n",
    "    - Transformacje:\n",
    "        - leniwe operacje\n",
    "        - przyjmują RDD i zwracają RDD\n",
    "\n",
    "- In-Memory - dane RDD przechowywane w pamięci\n",
    "- Immutable \n",
    "- Lazy evaluated\n",
    "- Parallel - przetwarzane równolegle\n",
    "- Partitioned - rozproszone \n",
    "\n",
    "## WAŻNE informacje !\n",
    "\n",
    "Ważne do zrozumienia działania SPARKA:\n",
    "\n",
    "Term                   |Definition\n",
    "----                   |-------\n",
    "RDD                    |Resilient Distributed Dataset\n",
    "Transformation         |Spark operation that produces an RDD\n",
    "Action                 |Spark operation that produces a local object\n",
    "Spark Job              |Sequence of transformations on data with a final action\n",
    "\n",
    "\n",
    "Dwie podstawowe metody tworzenia RDD:\n",
    "\n",
    "Method                      |Result\n",
    "----------                               |-------\n",
    "`sc.parallelize(array)`                  |Create RDD of elements of array (or list)\n",
    "`sc.textFile(path/to/file)`                      |Create RDD of lines from file\n",
    "\n",
    "Podstawowe transformacje\n",
    "\n",
    "Transformation Example                          |Result\n",
    "----------                               |-------\n",
    "`filter(lambda x: x % 2 == 0)`           |Discard non-even elements\n",
    "`map(lambda x: x * 2)`                   |Multiply each RDD element by `2`\n",
    "`map(lambda x: x.split())`               |Split each string into words\n",
    "`flatMap(lambda x: x.split())`           |Split each string into words and flatten sequence\n",
    "`sample(withReplacement=True,0.25)`      |Create sample of 25% of elements with replacement\n",
    "`union(rdd)`                             |Append `rdd` to existing RDD\n",
    "`distinct()`                             |Remove duplicates in RDD\n",
    "`sortBy(lambda x: x, ascending=False)`   |Sort elements in descending order\n",
    "\n",
    "Podstawowe akcje \n",
    "\n",
    "Action                             |Result\n",
    "----------                             |-------\n",
    "`collect()`                            |Convert RDD to in-memory list \n",
    "`take(3)`                              |First 3 elements of RDD \n",
    "`top(3)`                               |Top 3 elements of RDD\n",
    "`takeSample(withReplacement=True,3)`   |Create sample of 3 elements with replacement\n",
    "`sum()`                                |Find element sum (assumes numeric elements)\n",
    "`mean()`                               |Find element mean (assumes numeric elements)\n",
    "`stdev()`                              |Find element deviation (assumes numeric elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6289576-3208-4807-b05d-00167fc53f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keywords = ['Books', 'DVD', 'CD', 'PenDrive']\n",
    "\n",
    "key_rdd = sc.parallelize(keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31ed01c-beeb-49b9-ba26-f399b68578ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:287"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e7e1c7-1d27-42cd-a763-260b13ad459f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Books', 'DVD', 'CD', 'PenDrive']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff6d7d3-5aa2-4080-a3a2-f25e10147c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_small = key_rdd.map(lambda x: x.lower()) # transormacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98116f3a-ddf9-43f0-b5be-91d0e12a7dac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books', 'dvd', 'cd', 'pendrive']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key.lower() for key in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c30ea714-44a5-4e82-a787-262076bc1588",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2cc9d27-90e0-4648-9aef-2e406db50811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books', 'dvd', 'cd', 'pendrive']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_small.collect() # akcja "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21d8a4f2-f1a7-4b17-8c54-6ebdeabf7a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e567a0-e7df-42c3-af84-b69775435b1e",
   "metadata": {},
   "source": [
    "**Spark’s core data structure**\n",
    "\n",
    "✅: A low level object that lets Spark work its magic by splitting data across multiple nodes in the cluster.\n",
    "\n",
    "❌: However, RDDs are hard to work with directly, so we’ll be using the Spark DataFrame abstraction built on top of RDDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2226e6-dceb-4e33-83a2-f586f296d69b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MAP REDUCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19b4c64b-1ed1-4080-9a8a-8e262776b63a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"new\").getOrCreate()\n",
    "\n",
    "# otrzymanie obiektu SparkContex\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ec0bc5c-dc4d-4fde-90d0-172b3dde3f77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://1bdbcfb9b532:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>new</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff4fed4650>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8b73932-1fd1-4f79-8d07-1c16f8523450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# Word Count on RDD\n",
    "\n",
    "rdd = (sc.textFile(\"*.py\")\n",
    ".map(lambda x: re.findall(r\"[a-z']+\", x.lower()))\n",
    ".flatMap(lambda x: [(y, 1) for y in x])\n",
    ".reduceByKey(lambda x,y: x + y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e644466e-0374-4d0b-96d6-f22dc6011b08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[6] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3588fe7-26b1-4163-ae77-d3b029c89aac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('request', 6), ('errors', 5), ('end', 3), ('load', 7)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "496f4d7f-fc13-46be-9410-0bdba1890d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b1bf7-8f2d-4b8b-84ab-2759919fd028",
   "metadata": {},
   "source": [
    "## SPARK STREAMING\n",
    "\n",
    "Część Sparka odpowiedzialna za przetwarzanie danych w czasie rzeczywistym. \n",
    "\n",
    "\n",
    "<img src=\"https://spark.apache.org/docs/latest/img/streaming-arch.png\"/>\n",
    "\n",
    "Dane mogą pochodzić z różnych źródeł np. sokety TCP, Kafka, etc. \n",
    "Korzystając z poznanych już metod `map, reduce, join, oraz window` można w łatwy sposób generować przetwarzanie strumienia tak jaby był to nieskończony ciąg RDD. \n",
    "Ponadto nie ma problemu aby wywołać na strumieniu operacje ML czy wykresy. \n",
    "\n",
    "Cała procedura przedstawia się następująco: \n",
    "\n",
    "<img src=\"https://spark.apache.org/docs/latest/img/streaming-flow.png\"/>\n",
    "\n",
    "SPARK STREAMING w tej wersji wprowadza abstrakcje zwaną `discretized stream` *DStream* (reprezentuje sekwencję RDD).\n",
    "\n",
    "Operacje na DStream można wykonywać w API JAVA, SCALA, Python, R (nie wszystkie możliwości są dostępne dla Pythona). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c447df48-88db-4585-b6ac-3ddc1ee80d51",
   "metadata": {},
   "source": [
    "Spark Streaming potrzebuje minium 2 rdzenie.\n",
    "\n",
    "----\n",
    "- **StreamingContext(sparkContext, batchDuration)** - reprezentuje połączenie z klastrem i służy do tworzenia DStreamów, `batchDuration` wskazuje na granularność batch'y (w sekundach)\n",
    "- **socketTextStream(hostname, port)** - tworzy DStream na podstawie danych napływających ze wskazanego źródła TCP\n",
    "- **flatMap(f), map(f), reduceByKey(f)** - działają analogicznie jak w przypadku RDD z tym że tworzą nowe DStream'y\n",
    "- **pprint(n)** - printuje pierwsze `n` (domyślnie 10) elementów z każdego RDD wygenerowanego w DStream'ie\n",
    "- **StreamingContext.start()** - rozpoczyna działania na strumieniach\n",
    "- **StreamingContext.awaitTermination(timeout)** - oczekuje na zakończenie działań na strumieniach\n",
    "- **StreamingContext.stop(stopSparkContext, stopGraceFully)** - kończy działania na strumieniach\n",
    "\n",
    "Obiekt StreamingContext można wygenerować za pomocą obiektu SparkContext.\n",
    "\n",
    "\n",
    "<img src=\"https://spark.apache.org/docs/latest/img/streaming-dstream.png\"/>\n",
    "\n",
    "<img src=\"https://spark.apache.org/docs/latest/img/streaming-dstream-ops.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ef08b5b-573d-4c5e-bcc0-46a3eb879aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/streaming/context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "sc = SparkContext(\"local[2]\", \"NetworkWordCount\")\n",
    "ssc = StreamingContext(sc, 10)\n",
    "# DStream\n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "\n",
    "words = lines.flatMap(lambda x: re.findall(r\"[a-z']+\", x.lower()))\n",
    "wordCounts = words.map(lambda word: (word,1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "# wydrukuj pierwszy elemnet\n",
    "wordCounts.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21cefe88-f6ea-4f1a-9fa8-4f4ba7490318",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# before start run a stream data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m ssc\u001b[38;5;241m.\u001b[39mstart() \u001b[38;5;66;03m# Start the computation\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mssc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m ssc\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/streaming/context.py:239\u001b[0m, in \u001b[0;36mStreamingContext.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03mWait for the execution to stop.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    time to wait in seconds\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jssc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jssc\u001b[38;5;241m.\u001b[39mawaitTerminationOrTimeout(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2023-06-11 14:58:30\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2023-06-11 14:58:40\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# before start run a stream data\n",
    "ssc.start() # Start the computation\n",
    "ssc.awaitTermination()\n",
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338377f3-306b-4d98-b96e-8e2b405038cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w konsoli linuxowej netcat Nmap for windows\n",
    "!nc -lk 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3cf52-6309-4d19-b8b5-edb13eda3847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file start_stream.py\n",
    "\n",
    "from socket import *\n",
    "import time\n",
    "\n",
    "rdd = list()\n",
    "with open(\"MobyDick_full.txt\", 'r') as ad:\n",
    "    for line in ad:\n",
    "        rdd.append(line)\n",
    "\n",
    "HOST = 'localhost'\n",
    "PORT = 9999\n",
    "ADDR = (HOST, PORT)\n",
    "tcpSock = socket(AF_INET, SOCK_STREAM)\n",
    "tcpSock.bind(ADDR)\n",
    "tcpSock.listen(5)\n",
    "\n",
    "\n",
    "while True:\n",
    "    c, addr = tcpSock.accept()\n",
    "    print('got connection')\n",
    "    for line in rdd:\n",
    "        try:\n",
    "            c.send(line.encode())\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            break\n",
    "    c.close()\n",
    "    print('disconnected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c0c9288-2a2c-44aa-b609-ec2536b380e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2ccc9-3683-4881-bce0-df69edcf8704",
   "metadata": {},
   "source": [
    "## nowe podejscie\n",
    "\n",
    "Designed to behave a lot like a SQL table\n",
    "\n",
    "✅:\n",
    "- easier to understand,\n",
    "- Operations using DataFrames are automatically optimized\n",
    "- When using RDDs, it’s up to the data scientist to figure out the right way to optimize the query, but the DataFrame implementation has much of this optimization built in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "202f5db1-5f89-48f9-8c36-bce935fb6140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7412740-6656-4e45-9b92-79f536443ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "846d951c-2e03-4945-92a4-903a6e3b43a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://1bdbcfb9b532:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff4fee0950>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d818dbbe-bdd9-4835-a0a4-1c891657f7f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Przygotowanie danych\n",
    "\n",
    "```bash\n",
    "mkdir data\n",
    "cd data\n",
    "curl -L -o donation.zip http://bit.ly/1Aoywaq\n",
    "unzip donation.zip\n",
    "unzip 'block_*.zip'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52020d77-5668-4c0e-8644-b55ab89ea5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439db0f1-4bcf-42aa-9d7c-4a6a7ed18b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "178aaf0e-bebe-4ff5-bb1c-9f0dbad99eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create dataframe \n",
    "prev = spark.read.csv(\"data/block*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d6bb698-1ced-4793-963c-a31d00cd3b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string, _c10: string, _c11: string]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "693ff8ea-616d-4311-8885-4ae26efaaa01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5749142"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41c058c5-bd1b-481b-bf46-5a65643f9d08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| _c0| _c1|         _c2|         _c3|         _c4|         _c5|    _c6|   _c7|   _c8|   _c9|   _c10|    _c11|\n",
      "+----+----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "|id_1|id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "|3148|8326|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "+----+----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "365c9ee8-cae5-48d1-a883-b069efc16547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "|  _c0|  _c1|         _c2|         _c3|         _c4|         _c5|    _c6|   _c7|   _c8|   _c9|   _c10|    _c11|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| id_1| id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "| 3148| 8326|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|14055|94934|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|33948|34740|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|  946|71870|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|64880|71676|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|25739|45991|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|62415|93584|           1|           ?|           1|           ?|      1|     1|     1|     1|      0|    TRUE|\n",
      "|27995|31399|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "| 4909|12238|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|15161|16743|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|31703|37310|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|30213|36558|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|56596|56630|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|16481|21174|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|32649|37094|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|34268|37260|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|66117|69253|           1|           ?|           1|           ?|      1|     1|     1|     1|      0|    TRUE|\n",
      "| 2771|31982|           1|           ?|           1|           ?|      0|     1|     1|     1|      1|    TRUE|\n",
      "|23557|29673|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20a0dd84-da97-4b24-9e1c-74e6ef171b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dodatkowe opcje z header i wartości null \n",
    "parsed = spark.read.option(\"header\", \"true\")\\\n",
    ".option(\"nullValue\", \"?\")\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".csv(\"data/block*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0766a70-3f1b-48b6-92e4-7d9be59510c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('id_1', IntegerType(), True), StructField('id_2', IntegerType(), True), StructField('cmp_fname_c1', DoubleType(), True), StructField('cmp_fname_c2', DoubleType(), True), StructField('cmp_lname_c1', DoubleType(), True), StructField('cmp_lname_c2', DoubleType(), True), StructField('cmp_sex', IntegerType(), True), StructField('cmp_bd', IntegerType(), True), StructField('cmp_bm', IntegerType(), True), StructField('cmp_by', IntegerType(), True), StructField('cmp_plz', IntegerType(), True), StructField('is_match', BooleanType(), True)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a87eb67-cbf7-496f-8738-71669a4a6fba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| id_1| id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| 3148| 8326|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|14055|94934|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|33948|34740|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|  946|71870|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|64880|71676|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65c680d3-359c-44a7-8b2b-8af59796a2bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_1: integer (nullable = true)\n",
      " |-- id_2: integer (nullable = true)\n",
      " |-- cmp_fname_c1: double (nullable = true)\n",
      " |-- cmp_fname_c2: double (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_lname_c2: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a1cf3-1fa8-4f7e-b825-d012c95d5f14",
   "metadata": {},
   "source": [
    "## inne formaty \n",
    "\n",
    "- parquet\n",
    "- orc\n",
    "- json\n",
    "- jdbc\n",
    "- avro\n",
    "- yrxy\n",
    "- image\n",
    "- libsvm\n",
    "- binary\n",
    "- xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d3140ad-3878-4532-bc9e-50d7769c275b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parsed.write.format(\"parquet\").save(\"data/block.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14a12cbf-1008-4ef0-9e71-de98ee5956ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = spark.read.format(\"parquet\").load(\"data/block.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1cf44170-ea5d-49ca-9c56-557206cb6400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| id_1| id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| 3148| 8326|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|14055|94934|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82dc365-1b26-4926-953e-6c6bd0dc4b10",
   "metadata": {},
   "source": [
    "## schematy danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f50be2db-b995-4151-a874-f08bb0830acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "\n",
    "schema = StructType([\n",
    "  StructField(\"Date\", StringType(), True),\n",
    "  StructField(\"Open\", DoubleType(), True),\n",
    "  StructField(\"High\", DoubleType(), True),\n",
    "  StructField(\"Low\", DoubleType(), True),\n",
    "  StructField(\"Close\", DoubleType(), True),\n",
    "  StructField(\"Volume\", IntegerType(), True),\n",
    "  StructField(\"Name\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "ddlSchemaStr = \"\"\"Date STRING, Open FLOAT, High FLOAT, \n",
    "Low FLOAT, Close FLOAT, Voulme INT, Name String \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f10c3588-1ee7-49b1-9845-bb221fc4dd6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+---------+----+\n",
      "|      Date| Open| High|  Low|Close|   Voulme|Name|\n",
      "+----------+-----+-----+-----+-----+---------+----+\n",
      "|2006-01-03|10.34|10.68|10.32|10.68|201853036|AAPL|\n",
      "|2006-01-04|10.73|10.85|10.64|10.71|155225609|AAPL|\n",
      "|2006-01-05|10.69| 10.7|10.54|10.63|112396081|AAPL|\n",
      "|2006-01-06|10.75|10.96|10.65| 10.9|176139334|AAPL|\n",
      "|2006-01-09|10.96|11.03|10.82|10.86|168861224|AAPL|\n",
      "+----------+-----+-----+-----+-----+---------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.sql import SparkSession\n",
    "\n",
    "#spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.read.option(\"header\", True)\\\n",
    ".csv(\"data/stocks/AAPL_2006-01-01_to_2018-01-01.csv\", schema=ddlSchemaStr)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd8bd230-2016-41a2-a548-f55879fcd896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: float (nullable = true)\n",
      " |-- High: float (nullable = true)\n",
      " |-- Low: float (nullable = true)\n",
      " |-- Close: float (nullable = true)\n",
      " |-- Voulme: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a346b-4416-4132-a2a1-01b254722313",
   "metadata": {},
   "source": [
    "## dane niustrukturyzowane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "255a8136-c4ef-475d-816c-b2b648cfe665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.json\n"
     ]
    }
   ],
   "source": [
    "%%file test.json\n",
    "\n",
    "{\n",
    " \"id\": \"0001\",\n",
    " \"type\": \"donut\",\n",
    " \"name\": \"Cake\",\n",
    " \"ppu\": 0.55,\n",
    " \"batters\":\n",
    "  {\n",
    "   \"batter\":\n",
    "    [\n",
    "     { \"id\": \"1001\", \"type\": \"Regular\" },\n",
    "     { \"id\": \"1002\", \"type\": \"Chocolate\" },\n",
    "     { \"id\": \"1003\", \"type\": \"Blueberry\" }\n",
    "    ]\n",
    "  },\n",
    " \"topping\":\n",
    "  [\n",
    "   { \"id\": \"5001\", \"type\": \"None\" },\n",
    "   { \"id\": \"5002\", \"type\": \"Glazed\" },\n",
    "   { \"id\": \"5005\", \"type\": \"Sugar\" },\n",
    "   { \"id\": \"5007\", \"type\": \"Powdered Sugar\" },\n",
    "   { \"id\": \"5006\", \"type\": \"Chocolate with Sprinkles\" },\n",
    "   { \"id\": \"5003\", \"type\": \"Chocolate\" },\n",
    "   { \"id\": \"5004\", \"type\": \"Maple\" }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7247265e-4f34-40e6-ac48-447386840ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mixing dicts with non-Series may lead to ambiguous ordering.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:784\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:975\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 975\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mconvert_dtypes(\n\u001b[1;32m    978\u001b[0m         infer_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend\n\u001b[1;32m    979\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:1001\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    999\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1001\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:1134\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:1319\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1316\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1323\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1324\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[1;32m   1325\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1326\u001b[0m     }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/internals/construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/internals/construction.py:658\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m--> 658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n",
      "\u001b[0;31mValueError\u001b[0m: Mixing dicts with non-Series may lead to ambiguous ordering."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "055aa905-5dcc-40d0-aaf1-6a50bdb72ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rawDFjson = spark.read.json(\"test.json\", multiLine = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0cc8322f-142d-427a-ba3e-f7c6115f770d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- batters: struct (nullable = true)\n",
      " |    |-- batter: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- ppu: double (nullable = true)\n",
      " |-- topping: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawDFjson.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c90e9de-2ba7-4850-8ac2-b76e640cec08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------------------------------\n",
      " batters | {[{1001, Regular}, {1002, Chocolate}, {1003, Blueberry}]}                                                                                 \n",
      " id      | 0001                                                                                                                                      \n",
      " name    | Cake                                                                                                                                      \n",
      " ppu     | 0.55                                                                                                                                      \n",
      " topping | [{5001, None}, {5002, Glazed}, {5005, Sugar}, {5007, Powdered Sugar}, {5006, Chocolate with Sprinkles}, {5003, Chocolate}, {5004, Maple}] \n",
      " type    | donut                                                                                                                                     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawDFjson.show(1, False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40c2678b-48e9-4a52-bc24-af4e42fd587c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampleDF = rawDFjson.withColumnRenamed(\"id\", \"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d97db55c-463e-4ee5-a6f0-d0e9bac9762b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- batters: struct (nullable = true)\n",
      " |    |-- batter: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- ppu: double (nullable = true)\n",
      " |-- topping: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampleDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "802901f2-893f-4134-8842-0b21a15c1ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- batter: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batDF = sampleDF.select(\"key\", \"batters.batter\")\n",
    "batDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d3e6f473-c7a2-4566-85d3-c47b6251fd7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------------------------------------+\n",
      "|key |batter                                                 |\n",
      "+----+-------------------------------------------------------+\n",
      "|0001|[{1001, Regular}, {1002, Chocolate}, {1003, Blueberry}]|\n",
      "+----+-------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batDF.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e48e334e-c5da-4829-85e3-c133b403d8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "| key|       new_batter|\n",
      "+----+-----------------+\n",
      "|0001|  {1001, Regular}|\n",
      "|0001|{1002, Chocolate}|\n",
      "|0001|{1003, Blueberry}|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "bat2DF = batDF.select(\"key\", explode(\"batter\").alias(\"new_batter\"))\n",
    "bat2DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2263cab-5ccd-42c4-a901-1af3870ffbc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- new_batter: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bat2DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e8b49003-1c23-4166-a694-61178c832714",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+\n",
      "| key|  id|     type|\n",
      "+----+----+---------+\n",
      "|0001|1001|  Regular|\n",
      "|0001|1002|Chocolate|\n",
      "|0001|1003|Blueberry|\n",
      "+----+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bat2DF.select(\"key\", \"new_batter.*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58ad0947-f57d-450d-9488-9416121439a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---------+\n",
      "| key|bat_id| bat_type|\n",
      "+----+------+---------+\n",
      "|0001|  1001|  Regular|\n",
      "|0001|  1002|Chocolate|\n",
      "|0001|  1003|Blueberry|\n",
      "+----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalBatDF = (sampleDF\n",
    "        .select(\"key\",  \n",
    "explode(\"batters.batter\").alias(\"new_batter\"))\n",
    "        .select(\"key\", \"new_batter.*\")\n",
    "        .withColumnRenamed(\"id\", \"bat_id\")\n",
    "        .withColumnRenamed(\"type\", \"bat_type\"))\n",
    "finalBatDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c9d15ad7-f308-40b5-9cd4-343cdc89bf38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------------------------+\n",
      "|key |top_id|top_type                |\n",
      "+----+------+------------------------+\n",
      "|0001|5001  |None                    |\n",
      "|0001|5002  |Glazed                  |\n",
      "|0001|5005  |Sugar                   |\n",
      "|0001|5007  |Powdered Sugar          |\n",
      "|0001|5006  |Chocolate with Sprinkles|\n",
      "|0001|5003  |Chocolate               |\n",
      "|0001|5004  |Maple                   |\n",
      "+----+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topDF = (sampleDF\n",
    "        .select(\"key\", explode(\"topping\").alias(\"new_topping\"))\n",
    "        .select(\"key\", \"new_topping.*\")\n",
    "        .withColumnRenamed(\"id\", \"top_id\")\n",
    "        .withColumnRenamed(\"type\", \"top_type\")\n",
    "        )\n",
    "topDF.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8dd2f0-e666-45ae-b96c-9afe902068f4",
   "metadata": {},
   "source": [
    "## Eksploracyjna Analiza Danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d381357d-6514-4071-854d-1f9d26664b64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_1: integer (nullable = true)\n",
      " |-- id_2: integer (nullable = true)\n",
      " |-- cmp_fname_c1: double (nullable = true)\n",
      " |-- cmp_fname_c2: double (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_lname_c2: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# zweryfikuj schemat danych\n",
    "parsed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1cfa49c5-77a9-4141-9d65-b98802839819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id_1=3148, id_2=8326, cmp_fname_c1=1.0, cmp_fname_c2=None, cmp_lname_c1=1.0, cmp_lname_c2=None, cmp_sex=1, cmp_bd=1, cmp_bm=1, cmp_by=1, cmp_plz=1, is_match=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sprawdz wartosci dla pierwszego rzedu\n",
    "parsed.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f8c5c13f-e323-429b-a990-305934b5e535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5749132"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ile przypadkow \n",
    "parsed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "89429913-e699-413b-b65c-c4f6c954069b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id_1: int, id_2: int, cmp_fname_c1: double, cmp_fname_c2: double, cmp_lname_c1: double, cmp_lname_c2: double, cmp_sex: int, cmp_bd: int, cmp_bm: int, cmp_by: int, cmp_plz: int, is_match: boolean]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zapisz do pamieci na klastrze (1 maszyna) \n",
    "parsed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d147248c-2d26-4889-a9ca-a7d804981c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|is_match|  count|\n",
      "+--------+-------+\n",
      "|   false|5728201|\n",
      "|    true|  20931|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# target \"is_match\" liczba zgodnych i niezgodnych rekordow\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "parsed.groupBy(\"is_match\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "402ca5e1-e350-4476-be67-23ca6df4c92b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_match</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>5728201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>20931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_match    count\n",
       "0     False  5728201\n",
       "1      True    20931"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.groupBy(\"is_match\").count().orderBy(col(\"count\").desc()).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d5a8bd32-3efe-4acd-8d18-12f411b870f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sprawdz czy są braki danych \n",
    "from pyspark.sql.functions import count, when, isnan\n",
    "\n",
    "numeric_features = [t[0] for t in parsed.dtypes if t[1] == 'int' or t[1] == 'double']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "67013903-c1c5-4b5c-b047-65f566177a07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1</th>\n",
       "      <th>id_2</th>\n",
       "      <th>cmp_fname_c1</th>\n",
       "      <th>cmp_fname_c2</th>\n",
       "      <th>cmp_lname_c1</th>\n",
       "      <th>cmp_lname_c2</th>\n",
       "      <th>cmp_sex</th>\n",
       "      <th>cmp_bd</th>\n",
       "      <th>cmp_bm</th>\n",
       "      <th>cmp_by</th>\n",
       "      <th>cmp_plz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1007</td>\n",
       "      <td>5645434</td>\n",
       "      <td>0</td>\n",
       "      <td>5746668</td>\n",
       "      <td>0</td>\n",
       "      <td>795</td>\n",
       "      <td>795</td>\n",
       "      <td>795</td>\n",
       "      <td>12843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_1  id_2  cmp_fname_c1  cmp_fname_c2  cmp_lname_c1  cmp_lname_c2  \\\n",
       "0     0     0          1007       5645434             0       5746668   \n",
       "\n",
       "   cmp_sex  cmp_bd  cmp_bm  cmp_by  cmp_plz  \n",
       "0        0     795     795     795    12843  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = parsed.select(numeric_features)\n",
    "df.select([count(when(isnan(c)| col(c).isNull() , c)).alias(c) for c in df.columns]).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "46f772b3-5277-410f-a767-5d05424ef293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+\n",
      "|     avg(cmp_sex)|stddev_samp(cmp_sex)|stddev_pop(cmp_sex)|\n",
      "+-----------------+--------------------+-------------------+\n",
      "|0.955001381078048|  0.2073011111689795|0.20730109314007356|\n",
      "+-----------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inne agregaty agg\n",
    "from pyspark.sql.functions import avg, stddev, stddev_pop\n",
    "\n",
    "parsed.agg(avg(\"cmp_sex\"), stddev(\"cmp_sex\"), stddev_pop(\"cmp_sex\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a4c85b84-c0c0-4c53-8425-1c4acfbaca8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# polecenia sql - przypisanie nazwy dla silnika sql - tabela przejsciowa\n",
    "parsed.createOrReplaceTempView(\"dane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e8755985-ce9c-4112-9642-2cdcd4ad2a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|is_match|    cnt|\n",
      "+--------+-------+\n",
      "|   false|5728201|\n",
      "|    true|  20931|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" SELECT is_match, COUNT(*) cnt FROM dane group by is_match order by cnt DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "759ae876-52dc-4bcb-a50c-a8f6891194e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|summary|              id_1|              id_2|      cmp_fname_c1|      cmp_fname_c2|      cmp_lname_c1|       cmp_lname_c2|           cmp_sex|             cmp_bd|             cmp_bm|             cmp_by|            cmp_plz|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|  count|           5749132|           5749132|           5748125|            103698|           5749132|               2464|           5749132|            5748337|            5748337|            5748337|            5736289|\n",
      "|   mean| 33324.48559643438| 66587.43558331935|0.7129024704436274|0.9000176718903216|0.3156278193084133|0.31841283153174377| 0.955001381078048|0.22446526708507172|0.48885529849763504| 0.2227485966810923|0.00552866147434343|\n",
      "| stddev|23659.859374488213|23620.487613269885|0.3887583596162788|0.2713176105782331|0.3342336339615816|0.36856706620066537|0.2073011111689795| 0.4172297223846255| 0.4998758236779038|0.41609096298317344|0.07414914925420066|\n",
      "|    min|                 1|                 6|               0.0|               0.0|               0.0|                0.0|                 0|                  0|                  0|                  0|                  0|\n",
      "|    max|             99980|            100000|               1.0|               1.0|               1.0|                1.0|                 1|                  1|                  1|                  1|                  1|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# zbiorcze statystyki \n",
    "summary = parsed.describe()\n",
    "\n",
    "\n",
    "summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "434038ea-6bba-453d-89a3-7488891d9a56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_1</th>\n",
       "      <td>5749132</td>\n",
       "      <td>33324.48559643438</td>\n",
       "      <td>23659.859374488213</td>\n",
       "      <td>1</td>\n",
       "      <td>99980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_2</th>\n",
       "      <td>5749132</td>\n",
       "      <td>66587.43558331935</td>\n",
       "      <td>23620.487613269885</td>\n",
       "      <td>6</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_fname_c1</th>\n",
       "      <td>5748125</td>\n",
       "      <td>0.7129024704436274</td>\n",
       "      <td>0.3887583596162788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_fname_c2</th>\n",
       "      <td>103698</td>\n",
       "      <td>0.9000176718903216</td>\n",
       "      <td>0.2713176105782331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_lname_c1</th>\n",
       "      <td>5749132</td>\n",
       "      <td>0.3156278193084133</td>\n",
       "      <td>0.3342336339615816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_lname_c2</th>\n",
       "      <td>2464</td>\n",
       "      <td>0.31841283153174377</td>\n",
       "      <td>0.36856706620066537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_sex</th>\n",
       "      <td>5749132</td>\n",
       "      <td>0.955001381078048</td>\n",
       "      <td>0.2073011111689795</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_bd</th>\n",
       "      <td>5748337</td>\n",
       "      <td>0.22446526708507172</td>\n",
       "      <td>0.4172297223846255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_bm</th>\n",
       "      <td>5748337</td>\n",
       "      <td>0.48885529849763504</td>\n",
       "      <td>0.4998758236779038</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_by</th>\n",
       "      <td>5748337</td>\n",
       "      <td>0.2227485966810923</td>\n",
       "      <td>0.41609096298317344</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_plz</th>\n",
       "      <td>5736289</td>\n",
       "      <td>0.00552866147434343</td>\n",
       "      <td>0.07414914925420066</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                    1                    2    3       4\n",
       "summary         count                 mean               stddev  min     max\n",
       "id_1          5749132    33324.48559643438   23659.859374488213    1   99980\n",
       "id_2          5749132    66587.43558331935   23620.487613269885    6  100000\n",
       "cmp_fname_c1  5748125   0.7129024704436274   0.3887583596162788  0.0     1.0\n",
       "cmp_fname_c2   103698   0.9000176718903216   0.2713176105782331  0.0     1.0\n",
       "cmp_lname_c1  5749132   0.3156278193084133   0.3342336339615816  0.0     1.0\n",
       "cmp_lname_c2     2464  0.31841283153174377  0.36856706620066537  0.0     1.0\n",
       "cmp_sex       5749132    0.955001381078048   0.2073011111689795    0       1\n",
       "cmp_bd        5748337  0.22446526708507172   0.4172297223846255    0       1\n",
       "cmp_bm        5748337  0.48885529849763504   0.4998758236779038    0       1\n",
       "cmp_by        5748337   0.2227485966810923  0.41609096298317344    0       1\n",
       "cmp_plz       5736289  0.00552866147434343  0.07414914925420066    0       1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5bd5e87c-6758-411c-8de8-6fbb4399b9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|      cmp_fname_c1|      cmp_fname_c2|\n",
      "+-------+------------------+------------------+\n",
      "|  count|           5748125|            103698|\n",
      "|   mean|0.7129024704436274|0.9000176718903216|\n",
      "| stddev|0.3887583596162788|0.2713176105782331|\n",
      "|    min|               0.0|               0.0|\n",
      "|    max|               1.0|               1.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary.select(\"summary\", \"cmp_fname_c1\", \"cmp_fname_c2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729f99f-a5bb-49be-8aa7-4d5fa90b1107",
   "metadata": {},
   "source": [
    "> która zmienna lepiej opisze dane c1 czy c2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b9c8890c-2053-41d2-8b84-7198905b0cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# statystyki dla poszczegolnych klas\n",
    "\n",
    "# filtrowanie sql\n",
    "matches = parsed.where(\"is_match = true\")\n",
    "\n",
    "\n",
    "# filtrowanie pyspark\n",
    "misses = parsed.filter(col(\"is_match\") == False)\n",
    "\n",
    "match_summary = matches.describe()\n",
    "miss_summary = misses.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "600b49ca-6b22-42ef-9761-8283d06f60cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "|summary|              id_1|             id_2|        cmp_fname_c1|       cmp_fname_c2|       cmp_lname_c1|       cmp_lname_c2|            cmp_sex|             cmp_bd|             cmp_bm|              cmp_by|            cmp_plz|\n",
      "+-------+------------------+-----------------+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "|  count|             20931|            20931|               20922|               1333|              20931|                475|              20931|              20925|              20925|               20925|              20902|\n",
      "|   mean| 34575.72117911232|51259.95939037791|  0.9973163859635038| 0.9898900320318174| 0.9970152595958817|  0.969370167843852|  0.987291577086618| 0.9970848267622461| 0.9979450418160095|  0.9961290322580645| 0.9584250310975027|\n",
      "| stddev|21950.312851969127| 24345.7334537752|0.036506675848336785|0.08251973727615237|0.04311880753394512|0.15345280740388917|0.11201570591216432|0.05391487659807977|0.04528612745217063|0.062098048567310576|0.19962063345931927|\n",
      "|    min|                 5|                6|                 0.0|                0.0|                0.0|                0.0|                  0|                  0|                  0|                   0|                  0|\n",
      "|    max|             99946|            99996|                 1.0|                1.0|                1.0|                1.0|                  1|                  1|                  1|                   1|                  1|\n",
      "+-------+------------------+-----------------+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match_summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a542e7a-d26e-4c5e-877d-8dd28276e24d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+------------------+-------------------+-------------------+-------------------+------------------+-----------------+-------------------+--------------------+\n",
      "|summary|              id_1|              id_2|       cmp_fname_c1|      cmp_fname_c2|       cmp_lname_c1|       cmp_lname_c2|            cmp_sex|            cmp_bd|           cmp_bm|             cmp_by|             cmp_plz|\n",
      "+-------+------------------+------------------+-------------------+------------------+-------------------+-------------------+-------------------+------------------+-----------------+-------------------+--------------------+\n",
      "|  count|           5728201|           5728201|            5727203|            102365|            5728201|               1989|            5728201|           5727412|          5727412|            5727412|             5715387|\n",
      "|   mean|33319.913548075565| 66643.44259218557| 0.7118634802174252|0.8988473514090173|0.31313801133682906|0.16295544855122554| 0.9548833918362851|0.2216425149788421|0.486995347986141| 0.2199230647280133|0.002043781112285135|\n",
      "| stddev|23665.760130330764|23599.551728241124|0.38908060096985714|0.2727209029401023| 0.3322812130572706|0.19302366635287027|0.20755988859217656|0.4153518275558737| 0.49983089404939|0.41419432671429335| 0.04516197989362504|\n",
      "|    min|                 1|                30|                0.0|               0.0|                0.0|                0.0|                  0|                 0|                0|                  0|                   0|\n",
      "|    max|             99980|            100000|                1.0|               1.0|                1.0|                1.0|                  1|                 1|                1|                  1|                   1|\n",
      "+-------+------------------+------------------+-------------------+------------------+-------------------+-------------------+-------------------+------------------+-----------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "miss_summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "993ac050-e8e3-40d5-99ae-4609deac1ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+\n",
      "|summary|       cmp_fname_c1|      cmp_fname_c2|\n",
      "+-------+-------------------+------------------+\n",
      "|  count|            5727203|            102365|\n",
      "|   mean| 0.7118634802174252|0.8988473514090173|\n",
      "| stddev|0.38908060096985714|0.2727209029401023|\n",
      "|    min|                0.0|               0.0|\n",
      "|    max|                1.0|               1.0|\n",
      "+-------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "miss_summary.select(\"summary\", \"cmp_fname_c1\", \"cmp_fname_c2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83381456-981e-429d-8ef8-fadc253d1286",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tabele przestawne spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "67181430-52b9-4d20-aeb0-aeca52870160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_p = summary.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66802ea5-1cb8-431e-8c2e-74ede7327d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>id_1</th>\n",
       "      <th>id_2</th>\n",
       "      <th>cmp_fname_c1</th>\n",
       "      <th>cmp_fname_c2</th>\n",
       "      <th>cmp_lname_c1</th>\n",
       "      <th>cmp_lname_c2</th>\n",
       "      <th>cmp_sex</th>\n",
       "      <th>cmp_bd</th>\n",
       "      <th>cmp_bm</th>\n",
       "      <th>cmp_by</th>\n",
       "      <th>cmp_plz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>5749132</td>\n",
       "      <td>5749132</td>\n",
       "      <td>5748125</td>\n",
       "      <td>103698</td>\n",
       "      <td>5749132</td>\n",
       "      <td>2464</td>\n",
       "      <td>5749132</td>\n",
       "      <td>5748337</td>\n",
       "      <td>5748337</td>\n",
       "      <td>5748337</td>\n",
       "      <td>5736289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>33324.48559643438</td>\n",
       "      <td>66587.43558331935</td>\n",
       "      <td>0.7129024704436274</td>\n",
       "      <td>0.9000176718903216</td>\n",
       "      <td>0.3156278193084133</td>\n",
       "      <td>0.31841283153174377</td>\n",
       "      <td>0.955001381078048</td>\n",
       "      <td>0.22446526708507172</td>\n",
       "      <td>0.48885529849763504</td>\n",
       "      <td>0.2227485966810923</td>\n",
       "      <td>0.00552866147434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>23659.859374488213</td>\n",
       "      <td>23620.487613269885</td>\n",
       "      <td>0.3887583596162788</td>\n",
       "      <td>0.2713176105782331</td>\n",
       "      <td>0.3342336339615816</td>\n",
       "      <td>0.36856706620066537</td>\n",
       "      <td>0.2073011111689795</td>\n",
       "      <td>0.4172297223846255</td>\n",
       "      <td>0.4998758236779038</td>\n",
       "      <td>0.41609096298317344</td>\n",
       "      <td>0.07414914925420066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>99980</td>\n",
       "      <td>100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                id_1                id_2        cmp_fname_c1  \\\n",
       "0   count             5749132             5749132             5748125   \n",
       "1    mean   33324.48559643438   66587.43558331935  0.7129024704436274   \n",
       "2  stddev  23659.859374488213  23620.487613269885  0.3887583596162788   \n",
       "3     min                   1                   6                 0.0   \n",
       "4     max               99980              100000                 1.0   \n",
       "\n",
       "         cmp_fname_c2        cmp_lname_c1         cmp_lname_c2  \\\n",
       "0              103698             5749132                 2464   \n",
       "1  0.9000176718903216  0.3156278193084133  0.31841283153174377   \n",
       "2  0.2713176105782331  0.3342336339615816  0.36856706620066537   \n",
       "3                 0.0                 0.0                  0.0   \n",
       "4                 1.0                 1.0                  1.0   \n",
       "\n",
       "              cmp_sex               cmp_bd               cmp_bm  \\\n",
       "0             5749132              5748337              5748337   \n",
       "1   0.955001381078048  0.22446526708507172  0.48885529849763504   \n",
       "2  0.2073011111689795   0.4172297223846255   0.4998758236779038   \n",
       "3                   0                    0                    0   \n",
       "4                   1                    1                    1   \n",
       "\n",
       "                cmp_by              cmp_plz  \n",
       "0              5748337              5736289  \n",
       "1   0.2227485966810923  0.00552866147434343  \n",
       "2  0.41609096298317344  0.07414914925420066  \n",
       "3                    0                    0  \n",
       "4                    1                    1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e73d61b6-0092-4d85-b9bc-ec23331bbc3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 12)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9e3eacb6-2baa-46c0-b964-2c207b563333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_p = summary_p.set_index('summary').transpose().reset_index()\n",
    "summary_p = summary_p.rename(columns={'index':'field'})\n",
    "summary_p = summary_p.rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b64008dc-0d3c-4dbd-87eb-40b4d5c89589",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-------------------+-------------------+---+------+\n",
      "|       field|  count|               mean|             stddev|min|   max|\n",
      "+------------+-------+-------------------+-------------------+---+------+\n",
      "|        id_1|5749132|  33324.48559643438| 23659.859374488213|  1| 99980|\n",
      "|        id_2|5749132|  66587.43558331935| 23620.487613269885|  6|100000|\n",
      "|cmp_fname_c1|5748125| 0.7129024704436274| 0.3887583596162788|0.0|   1.0|\n",
      "|cmp_fname_c2| 103698| 0.9000176718903216| 0.2713176105782331|0.0|   1.0|\n",
      "|cmp_lname_c1|5749132| 0.3156278193084133| 0.3342336339615816|0.0|   1.0|\n",
      "|cmp_lname_c2|   2464|0.31841283153174377|0.36856706620066537|0.0|   1.0|\n",
      "|     cmp_sex|5749132|  0.955001381078048| 0.2073011111689795|  0|     1|\n",
      "|      cmp_bd|5748337|0.22446526708507172| 0.4172297223846255|  0|     1|\n",
      "|      cmp_bm|5748337|0.48885529849763504| 0.4998758236779038|  0|     1|\n",
      "|      cmp_by|5748337| 0.2227485966810923|0.41609096298317344|  0|     1|\n",
      "|     cmp_plz|5736289|0.00552866147434343|0.07414914925420066|  0|     1|\n",
      "+------------+-------+-------------------+-------------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summaryT = spark.createDataFrame(summary_p)\n",
    "summaryT.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0a6ec544-a601-45a2-8377-c751096dbbb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- field: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- mean: string (nullable = true)\n",
      " |-- stddev: string (nullable = true)\n",
      " |-- min: string (nullable = true)\n",
      " |-- max: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summaryT.printSchema() # czy dobre typy danych ?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e4f4fc15-00ad-4810-92b9-15e47a52c5f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "for c in summaryT.columns:\n",
    "    if c == 'field':\n",
    "        continue\n",
    "    summaryT = summaryT.withColumn(c, summaryT[c].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4895da90-8627-401c-aab5-8c54952e482d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- field: string (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- mean: double (nullable = true)\n",
      " |-- stddev: double (nullable = true)\n",
      " |-- min: double (nullable = true)\n",
      " |-- max: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summaryT.printSchema() # teraz lepiej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "27182754-f6e9-4dd3-9695-cfaf484e0e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wykonaj to samo dla tabel match i miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "569a5119-19ae-45f7-9496-30fd3c2ddb90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pivot_summary(desc):\n",
    "    desc_p = desc.toPandas()\n",
    "    desc_p = desc_p.set_index('summary').transpose().reset_index()\n",
    "    desc_p = desc_p.rename(columns={'index':'field'})\n",
    "    desc_p = desc_p.rename_axis(None, axis=1)\n",
    "    descT = spark.createDataFrame(desc_p)\n",
    "    for c in descT.columns:\n",
    "        if c == 'field':\n",
    "            continue\n",
    "        else:\n",
    "            descT = descT.withColumn(c, descT[c].cast(DoubleType()))\n",
    "    return descT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "65e47639-1638-488e-93b9-8336d8795a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "match_summaryT = pivot_summary(match_summary)\n",
    "miss_summaryT = pivot_summary(miss_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1099c-0fa5-4103-9173-baf55e82e9c8",
   "metadata": {},
   "source": [
    "## złączenia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5bebb104-709d-4336-ac14-0fdc4a56d2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "match_summaryT.createOrReplaceTempView(\"match_s\")\n",
    "miss_summaryT.createOrReplaceTempView(\"miss_s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "72af2e16-4103-4e9c-a8aa-048faa368fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+--------------------+\n",
      "|       field|    total|               delta|\n",
      "+------------+---------+--------------------+\n",
      "|     cmp_plz|5736289.0|  0.9563812499852176|\n",
      "|cmp_lname_c2|   2464.0|  0.8064147192926264|\n",
      "|      cmp_by|5748337.0|  0.7762059675300512|\n",
      "|      cmp_bd|5748337.0|   0.775442311783404|\n",
      "|cmp_lname_c1|5749132.0|  0.6838772482590526|\n",
      "|      cmp_bm|5748337.0|  0.5109496938298685|\n",
      "|cmp_fname_c1|5748125.0|  0.2854529057460786|\n",
      "|cmp_fname_c2| 103698.0| 0.09104268062280008|\n",
      "|     cmp_sex|5749132.0|0.032408185250332844|\n",
      "+------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "Select a.field, a.count + b.count total, a.mean - b.mean delta\n",
    "from match_s a inner join miss_s b on a.field = b.field \n",
    "where a.field not in (\"id_1\", \"id_2\")\n",
    "order by delta DESC, total DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0277a437-d0cc-46ee-8952-38750b469cea",
   "metadata": {
    "tags": []
   },
   "source": [
    "> do modelu : `cmp_plz`, `cmp_by`, `cmp_bd`, `cmp_lname_c1`, `cmp_bm`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1e7b97e3-2105-465b-9058-08e301ebc13c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## score = suma zmiennych\n",
    "zmienne = ['cmp_plz','cmp_by','cmp_bd','cmp_lname_c1','cmp_bm']\n",
    "suma = \" + \".join(zmienne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "892fed78-d456-41f2-af73-67ca86235ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cmp_plz + cmp_by + cmp_bd + cmp_lname_c1 + cmp_bm'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0d22ebab-bde5-4eb2-8c88-1809e1e2fa96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f86353a4-59f6-4669-9da5-111a37b8176d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scored = parsed.fillna(0, subset=zmienne)\\\n",
    ".withColumn('score', expr(suma))\\\n",
    ".select('score','is_match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f1b9d3f7-7f41-4d47-9233-69a12e973342",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|score|is_match|\n",
      "+-----+--------+\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  4.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  4.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scored.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "87d396a7-60b7-4436-a39a-551fe4a2e9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ocena wartosci progowej\n",
    "def crossTabs(scored, t):\n",
    "    return scored.selectExpr(f\"score >= {t} as above\", \"is_match\")\\\n",
    "    .groupBy(\"above\").pivot(\"is_match\",(\"true\",\"false\"))\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9113d0cd-821b-4ddd-9d65-cf9f6b3c9bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+\n",
      "|above| true|  false|\n",
      "+-----+-----+-------+\n",
      "| true|20871|    637|\n",
      "|false|   60|5727564|\n",
      "+-----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crossTabs(scored, 4.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1a2b8629-5751-4546-9463-dd024e9cd396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+\n",
      "|above| true|  false|\n",
      "+-----+-----+-------+\n",
      "| true|20916| 315213|\n",
      "|false|   15|5412988|\n",
      "+-----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crossTabs(scored, 3.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0b2c0dfb-d4b7-4912-82ae-e6f2ef3d8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdx train, test = labelDF.randomSplit([0.8, 0.2], seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "359d7129-a7ae-4f48-9104-b33555022b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "791ede49-1d18-48a1-be16-d2dc2a46d8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_cols = zmienne\n",
    "va = VectorAssembler(inputCols=input_cols, outputCol=\"featuresVector\", handleInvalid=\"skip\")\n",
    "\n",
    "train_X = va.transform(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0afdc9c1-1cdd-4f9a-a8df-5659014d20c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+------------+------+--------+--------------------+\n",
      "|cmp_plz|cmp_by|cmp_bd|cmp_lname_c1|cmp_bm|is_match|      featuresVector|\n",
      "+-------+------+------+------------+------+--------+--------------------+\n",
      "|      1|     1|     1|         1.0|     1|    true|[1.0,1.0,1.0,1.0,...|\n",
      "|      1|     1|     1|         1.0|     1|    true|[1.0,1.0,1.0,1.0,...|\n",
      "|      1|     1|     1|         1.0|     1|    true|[1.0,1.0,1.0,1.0,...|\n",
      "|      1|     1|     1|         1.0|     1|    true|[1.0,1.0,1.0,1.0,...|\n",
      "|      1|     1|     1|         1.0|     1|    true|[1.0,1.0,1.0,1.0,...|\n",
      "+-------+------+------+------------+------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X.select(zmienne +[\"is_match\", \"featuresVector\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cb730900-197a-4b2e-a4d5-6fdb6a7806c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "92f47991-8912-4694-b85c-bc8c5a11b252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def isTrue(x):\n",
    "    if x == True:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "def isTrue2(x):\n",
    "    return int(x)\n",
    "    \n",
    "new_f = udf(isTrue, IntegerType())\n",
    "\n",
    "new_f2 = udf(isTrue2, IntegerType())\n",
    "\n",
    "new_f3 = udf(lambda y: 1 if y==True else 0, IntegerType()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9bb92602-4db7-40b9-b3f2-d42e92dabf12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+---+\n",
      "|is_match| t1| t2| t3|\n",
      "+--------+---+---+---+\n",
      "|    true|  1|  1|  1|\n",
      "|    true|  1|  1|  1|\n",
      "|    true|  1|  1|  1|\n",
      "|    true|  1|  1|  1|\n",
      "|    true|  1|  1|  1|\n",
      "|    true|  1|  1|  1|\n",
      "|    true|  1|  1|  1|\n",
      "|    true|  1|  1|  1|\n",
      "|    true|  1|  1|  1|\n",
      "|    true|  1|  1|  1|\n",
      "+--------+---+---+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_x = train_X.withColumn(\"target\", new_f(\"is_match\"))\n",
    "\n",
    "targety = train_X.withColumn(\"t1\", new_f(\"is_match\"))\\\n",
    ".withColumn(\"t2\", new_f2(\"is_match\"))\\\n",
    ".withColumn(\"t3\", new_f3(\"is_match\")).select(\"is_match\", \"t1\",\"t2\",\"t3\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b97cd974-a552-4f35-97cc-d26b2e8de209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(seed=32, labelCol=\"target\", \n",
    "                             featuresCol=\"featuresVector\", \n",
    "                             predictionCol=\"prediction\")\n",
    "model = clf.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c9fe87fb-d8ac-43b0-bfcf-02c28140320d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_5d1495b50bc6, depth=5, numNodes=25, numClasses=2, numFeatures=5\n",
      "  If (feature 0 <= 0.5)\n",
      "   If (feature 3 <= 0.9545454545454545)\n",
      "    Predict: 0.0\n",
      "   Else (feature 3 > 0.9545454545454545)\n",
      "    If (feature 1 <= 0.5)\n",
      "     Predict: 0.0\n",
      "    Else (feature 1 > 0.5)\n",
      "     If (feature 2 <= 0.5)\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 > 0.5)\n",
      "      If (feature 4 <= 0.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 4 > 0.5)\n",
      "       Predict: 1.0\n",
      "  Else (feature 0 > 0.5)\n",
      "   If (feature 2 <= 0.5)\n",
      "    If (feature 3 <= 0.9545454545454545)\n",
      "     Predict: 0.0\n",
      "    Else (feature 3 > 0.9545454545454545)\n",
      "     If (feature 1 <= 0.5)\n",
      "      Predict: 0.0\n",
      "     Else (feature 1 > 0.5)\n",
      "      If (feature 4 <= 0.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 4 > 0.5)\n",
      "       Predict: 1.0\n",
      "   Else (feature 2 > 0.5)\n",
      "    If (feature 3 <= 0.707142857142857)\n",
      "     Predict: 0.0\n",
      "    Else (feature 3 > 0.707142857142857)\n",
      "     If (feature 4 <= 0.5)\n",
      "      If (feature 1 <= 0.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 1 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 4 > 0.5)\n",
      "      Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a9e8853f-8e48-4788-b45c-afd4c31b93ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cmp_plz</th>\n",
       "      <td>0.610380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_bd</th>\n",
       "      <td>0.276839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_lname_c1</th>\n",
       "      <td>0.092162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_bm</th>\n",
       "      <td>0.016819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmp_by</th>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              importance\n",
       "cmp_plz         0.610380\n",
       "cmp_bd          0.276839\n",
       "cmp_lname_c1    0.092162\n",
       "cmp_bm          0.016819\n",
       "cmp_by          0.003800"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.DataFrame(model.featureImportances.toArray(),index = zmienne, columns=['importance'])\\\n",
    ".sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9c1f28e8-9e0e-4eff-b0d7-517cf84df781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------------------------------------+----------+\n",
      "|target|rawPrediction |probability                             |prediction|\n",
      "+------+--------------+----------------------------------------+----------+\n",
      "|1     |[16.0,19897.0]|[8.034952041380003E-4,0.999196504795862]|1.0       |\n",
      "|1     |[16.0,19897.0]|[8.034952041380003E-4,0.999196504795862]|1.0       |\n",
      "+------+--------------+----------------------------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(train_x).select([\"target\",\"rawPrediction\",\"probability\",\"prediction\"]).show(2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc879183-0803-4e4b-9d28-ed9d62f169a0",
   "metadata": {},
   "source": [
    "# STREAM on DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6561f6c7-0633-489d-8944-55cf6262c6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting streamWordCount.py\n"
     ]
    }
   ],
   "source": [
    "%%file streamWordCount.py\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.appName(\"Stream_DF\").getOrCreate()\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "    \n",
    "    lines = (spark\n",
    "         .readStream\n",
    "         .format(\"socket\")\n",
    "         .option(\"host\", \"localhost\")\n",
    "         .option(\"port\", 9999)\n",
    "         .load())\n",
    "\n",
    "    words = lines.select(explode(split(lines.value, \" \")).alias(\"word\"))\n",
    "    word_counts = words.groupBy(\"word\").count()\n",
    "\n",
    "    streamingQuery = (word_counts\n",
    "         .writeStream\n",
    "         .format(\"console\")\n",
    "         .outputMode(\"complete\")\n",
    "         .trigger(processingTime=\"5 second\")\n",
    "         .start())\n",
    "\n",
    "    streamingQuery.awaitTermination()\n",
    "         \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6546079-60e1-421a-a0fc-d5e623896705",
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-submit streamWordCount.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
